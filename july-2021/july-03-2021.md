Along the lines of compressing probability networks from yesterday, I was thinking about classifications, typing, etc as they relate to probability

---

Firstly, one thing I wanted to talk about is what you might call a knowledge cascade[^1]. This is a hypothetical phenomenon in a system which does inference on its subsystems informed by the states in other subsystems. When there are enough subsystems' states known with high enough confidence, there is probably enough evidence to infer other, correlated subsystems' states to a high enough confidence. It stands to reason that the more subsystems there are, the more likely that a new subsystem will have its state inferred to high confidence. So presumably there is some threshold, or set of thresholds, to the number of known subsystem states that once passed will guarantee all or almost all of the other subsystems' states will be confidently inferred as the system infers one state after another, increasing the number of known states and making the next state even more likely to be confidently inferred

So this is like If you have a system with subsystems $s_i$ with current states $x_i$ then you are using your collected data that has been rendered down to $P\left(q=z_k \land \bigwedge_i s_i = x_i\right)$ to predict the which of the values $z_k$ another subsystem $q$ has. This is equivalent to (using a variant of the previous notation): $P\left(z_k\,|\, \bigwedge_i x_i\right)\, P\left(\bigwedge_i x_i\right)$ and if we are sure that $P\left(\bigwedge_i x_i\right) \approx 1$ because each of the $P(x_i)\approx 1$ is given, then this is like just $P\left(z_k\,|\, \bigwedge_i x_i \right)$. But we have a bunch of these, ie: $v = \left(P(z_k\,|\,\bigwedge_i x_i)\right)_k$ and we want this vector $v$ to be unit-vectorized to maximize the probability of a single $z_k$ value from the set of them

Note, again, itc the expressions involving the conditional probability above aren't always valid because we are only looking at the case where certain states are known in the other subsystems. I'm also assuming that $\sum_k P\left(z_k\,|\,\bigwedge_i x_i\right) = \sum_k v_k = 1$. This is all a pretty loose treatment and is more descriptive than rigorous

If $v$ becomes more unit-vector-like when there are more $x_i$ available, then we specifically want more $x_i$ to be available. There's probably a way to  ---



---

As another related aside, if you have a vector $v$ such that $\sum_i v_i = 1$, then is the quantity $s = \sum_i v_i^2$ maximized when $v$ is a unit vector?

Yes, because of this line of reasoning: squaring one we get:

$$(\sum_i v_i)^2 = \sum_i v_i^2 + \sum_{i \ne j} v_i v_j = 1^2 = 1 = s + \sum_{i \ne j} v_i v_j$$

And since all $v_i \in [0, 1]$ and so all $v_i^2 \in [0,1]$ and all $v_i^2 \le v_i$ on this interval, the largest value $s$ can have is $s = 1$. So $s$ is maximized when $s = 1$ and so $s + \sum_{i \ne j} v_i v_j = 1$ implies $\sum_{i \ne j} v_i v_j = 0$

This means that in every pair $v_i,v_j$ where $i \ne j$ either $v_i = 0$ or $v_j = 0$ or both. But if we assume that there are two $v_i,v_j \ne 0$ then $v_i v_j \ne 0$ so only one $v_i = 0$

This means that $v = \hat x_i \delta$ and so $s = \delta^2 = 1$ so $\delta = 1$, and so $v = \hat x_i$ maximizes $s$ 

This is probably consequential for a number of reasons. One is that you can encourage a softmaxed vector in an ANN to be a unit vector by including a loss term like $1-\sum_i v_i^2$ which tries to maximize the sum of squares of the vector. Though I think $1-\max v$ is faster


---

[^1]: In the same vein of an industrial cascade / automation cascade: where you automate enough of your own behaviors that the machines you make can create and maintain themselves, and that system of machines then can provide literally every service and product you want because they have essentially unlimited industrial capacity and labor force. It's like where your all time personal *work capacity* -- the amount of work (whatever work means itc) you do over all time because of the tools you use and your own abilities -- reaches a finite time singularity. The core idea is that you will end up with ai-slaved drones mining the asteroid belt and producing literally everything everyone could ever want; and ai and ai-slaved drones providing literally every service everyone could ever want. This isn't just fantasy, it's conceivably actually possible. The socioeconomic effects of this, and their values, are debatable but I always make the assumption that an industrial / automation cascade is an **extraordinarily** good thing for society and civilization
