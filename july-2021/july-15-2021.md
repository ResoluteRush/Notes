
I was walking yesterday evening and I had a bunch of interesting ideas, heres one about encoded functions in models[^1] which potentially *massively* simplifies how models function

---

Functions of any arity can be built using the encoded equivalent of recursive currying mediated by a universal binary function:

Nary functions like: $f(x_1,x_2,\dots,x_n)$ are equivalent to $y_n$ where $y_{i+1} = \Psi(y_i, x_i)$ and $y_0 = f_e$,  $f_e$ is $f$'s representation in the system, and where $\Psi$ is the universal binary function. This is also like: $f(x_1,\dots) = \Psi(\cdot,x_n) \circ \Psi(\cdot, x_{n-1}) \circ \dots \circ \Psi(\cdot, x_2) \circ \Psi(f_e, x_1) = \Psi(\Psi(\dots\Psi(f_e,x_1),x_2),\dots,x_n)$

Notice that if $\Psi$ is an ANN this makes $f$'s encoding equivalent to an RNN in the system

Unary functions are like: $f(x) = \Psi(f_e, x)$ 

Nonary functions are like: $f() = \Psi(f_e, \emptyset)$ where $\emptyset$ is the null object. Note: there may be some additional hidden state that makes nonary functions make sense, otherwise they just return the same output every time

I really probably shouldn't say this, but incidentally, notice the analogy with cons trees in lisp

---

Why is this important? Because models with functions that have arbitrary numbers of arguments have too-complex interfaces for automation. The smaller the interface for a model as interpreted as a module[^2], the easier it is to work with. If a model's interface just accepts a sequence of representations, that is much much simpler than having (I don't even know) however many different cases for different numbers of function arguments, or for individual functions. This method is also much more flexible because it isn't fundamentally limited by function names (you would otherwise have to have human-semantic function representations), number of arguments, and forms of representations (you could potentially force certain representations in the model into acting as internal private functions, which would otherwise be too complex or impossible with a less general interface)

This method is also more flexible because the objects themselves can be correlated to act like functions, and so there is potentially a natural purpose for every model. eg: a model that *just* adds two positions to make a third position can use $\Psi$ as the binary addition function; a more complex model with multiple encoded functions may actually also use $\Psi$ for addition between non-function representations, if it makes sense to

---

Just a note: you can construct UCEs for generating the representations in a model, but the model's functions are FCEs (from reps to modified reps). This probably means you need another function which is equivalent to the model's functions upstream to train those FCEs. I'm not sure how that works yet because it seems time evolution is the only fundamental source of FCEs (besides lateral FCEs for eg inference). Does this mean all models' functions are trained on time evolutions of their parent model(s)? Of course once you've bootstrapped intelligence the system can do its own internal correlating and define its models however it wants. But what is the fundamental source of correlation of sub-agi models?

---

Another thing I was considering today: just like there are object representations[^3], there may also be process representations, which represent whole dynamic processes over time. Probably the entire process has a single rep in the sense of being invariant to time evolution $f\ p\ s = f\ s$ [^4]

Just like object reps can be composed, process reps can also likely be composed. And just like object reps can be formed through composition of analogs, process reps can also likely be formed through composition of some analog of analogs

Also, just like certain object reps are structures in the sense of being indexable ($f(x, c) = y$), it's likely that certain process reps are also structures and can be indexed

Consider function subset types `foo in A B C D ...`; functions inevitably have some representation in intelligent systems, and its likely that certain members (in the sense of structure indexation) of process reps are function reps

Process reps also can probably be used to generate function reps through indexation as a form of contextualized dredding: $e(p, c) = f$ where $p$ is the process rep, $c$ is the query / context, $f$ is the function rep, and $e$ is lossy. Presumably these function reps would be used to evolve a state such that the encoder to the process rep is invariant to $f$. Or equivalently, $e$ returns an object rep for the state of the system the process rep represents

---

[^1]: A model is a set of objects with some nary functions between them. Usually these are like a lossy encoding of another set to specifically reduce the amount of information the system has to work with. eg: you may flatten a 3-dimensional world to a 2-dimensional map so you can more easily work with object in that context. The main idea is essentially equivalent to [models](https://en.wikipedia.org/wiki/Model) in the more traditional sense, and is generally about reducing the amount of information you have to work with. Since models require the three top-level components of intelligence: translation from external to internal semantics, internal functions, and translation from internal to external semantics; this means all intelligent systems are models

[^2]: Module: a black box with a relatively simple interface

[^3]: An object representation is mostly equivalent to a set of objects which are all equivalent under the function that translates them to their representation. $\forall x, y \in X, f(x) = f(y)$. Object representation are specifically for equating objects and encoding those objects in an information-reduced way

[^4]: Notice, if this is the best way to define a process representation, that again, what defines a representation is an invariance / equivalence relationship (which is fundamentally lossy btw)
